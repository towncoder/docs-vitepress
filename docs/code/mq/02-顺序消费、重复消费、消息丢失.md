一文解决MQ顺序消费、重复消费、消息丢失三大问题。

哈喽，大家好，我是一条。

今天来聊聊消息队列，首先消息队列的三大作用是异步、解耦、削峰，是我们实现分布式系统高可用的一大利器。

但是引入消息队列，也会增加系统的复杂性，最常见的问题就有**顺序消费、重复消费、消息丢失**，也是面试中非常爱问的问题。

而不同的消息队列，处理这三种问题的方式又略有不同，目前主流的消息队列有RabbitMQ、RocketMQ、Kafka。

三大问题，三种消息队列，组合起来就是**九大面试常考点**，本篇文章，通通帮你解决！



## 顺序消费

> 顺序消费说的就是如何保证消息不乱序，像队列一样，先进先出。
>
> 在实际业务中，并不是所有时候都要考虑这个问题，如果消息之间没有关联性或依赖性，那乱序问题也不大。

既然要解决问题，我们就先来分析一下，什么情况会导致乱序，问题出在哪里？就好对症下药了。

![](https://yitiaoit.oss-cn-beijing.aliyuncs.com/img/image-20220707121343257.png)

首先生产者这里要保证生产出的消息是顺序的，比如你得先有订单再有支付，本身上游投递来的消息顺序就不对，那MQ也无能为力。

那MQ本身是个队列，先进先出原则，在同步发送的前提应该是不会有问题的，异步发送的话就不好说了。

消费者这边问题就大了，因为经常会有一个队列或者一个topic的消息是多线程也就是多个消费者消费的。比如即使是先发订单消息，再发支付消息，但是 consumer2 先收到了支付消息， consumer1 还没收到订单消息创建订单，这就嗝屁了。

从上面的分析，我们可以得出结论：顺序消费的重点在消费端，需要根据具体的业务来制定相应措施，比如 consumer2 先收到了支付消息，可以先将消息保存在一张本地表或者缓存中，然后定时扫描订单表，找到了订单id之后再去进行支付操作。

那从MQ看能否对顺序消费问题做一些处理呢，我们继续往下看。

### RabbitMQ

RabbitMQ本身是没有绝对的消息顺序机制的，单个 queue 在多消费者下不能保证其先后顺序。所以我们只能在设计上下功夫。

解决起来也很简单，就是让一个 queue 只对应一个消费者，将消息发到多个 queue 里。比如下单、支付、物流三个消息为一组。那对订单 id 取模来确定投递到哪个队列，同时要保证投递的原子性（加锁）。那对消费者来说，自己消费的队列内都是顺序的了。

![](https://yitiaoit.oss-cn-beijing.aliyuncs.com/img/image-20220707131201944.png)

那只有一个消费者，消费的太慢怎么办呢？**可千万不要轻易增加消费者**！

一个 queue，但是对应一个 consumer，然后在这个 consumer 内部用内存队列（List就可以）做排队，然后分发给底层不同的 worker 线程来处理。

### RocketMQ

RocketMQ 可以严格的保证消息有序，可以分为分区有序或者全局有序。

**分区有序**

和 RabbitMQ 有些相似，还是要要保证同一类型的消息投递到同一个 MessageQueue ，RocketMQ给我们提供了选择 MessageQueue 的类`MessageQueueSelector`。见代码：

```java
SendResult result = producer.send(message, new MessageQueueSelector() {
            @Override
            public MessageQueue select(List<MessageQueue> mqs, Message msg, Object orderId) {
                Integer id = (Integer) orderId;
                int index = id % mqs.size();
                return mqs.get(index);
            }
        }, orderId);
```

> 注意：
>
> 实际上，采用队列选择器的方法不能保证消息的严格顺序，我们的目的是将消息发送到同一个队列中，如果某个 broker 挂了，那么队列就会减少一部分，如果采用取余的方式投递，将可能导致同一个业务中的不同消息被发送到不同的队列中，导致同一个业务的不同消息被存入不同的队列中，短暂的造成部分消息无序。同样的，如果增加了服务器，那么也会造成短暂的造成部分消息无序。
>
> 所以问题的关键在于**取余**，这块我想到的办法就是用**一致性哈希算法**，又更好的解决办法后面再补充。

保证生产者的有序投递之后，消费者这边也要求只有一个吗？

RocketMQ 提供的集群模式天然具有负载均衡功能，即一个 MessageQueue 只会被 ConsumerGroup 中的一个消费者订阅。这里面的分配策略由`AllocateMessageQueueStrategy.class`来帮我们实现，具体就等到源码解析时再看。

那这样看一个消费者效率也太低了吧，其实不然。

RocketMQ 给我们提供了两种消费策略：有序消费模式`MessageListenerOrderly`和并发消费模式`MessageListenerConcurrently`。

```java
// 监听
        consumer.registerMessageListener(new MessageListenerConcurrently() {
            @Override
            public ConsumeConcurrentlyStatus consumeMessage(
                    List<MessageExt> msgList,
                    ConsumeConcurrentlyContext consumeConcurrentlyContext
            ) {
                return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
            }
        });
```



在消费的时候，肯定是要保证有序消费模式，但这种模式也并非是单线程的。

并发模式是拉取到新消息之后就提交到线程池去消费，有序模式则是通过加分布式锁和本地锁保证同时只有一条线程去消费一个队列上的数据。

那我们就再来看一下**加锁机制**：

消费者在进行某个队列的消息拉取时首先向 Broker 服务器申请队列锁，如果申请到琐，则拉取消息，否则放弃消息拉取，等到下一个队列负载周期(20s)再试。

**这一个锁使得一个 MessageQueue 同一个时刻只能被一个消费客户端消费**，防止因为队列负载均衡导致消息重复消费。

假设消费者对 MessageQueue 的加锁已经成功，那么会开始拉取消息，拉取到消息后同样会提交到消费端的线程池进行消费。但在本地消费之前，会先获取该 MessageQueue 对应的锁对象，获取到锁对象后，使用 synchronized 阻塞式的申请线程级独占锁。

**这一个锁使得来自同一个 MessageQueue 的消息在本地的同一个时刻只能被一个消费客户端中的一个线程顺序的消费**。

在本地加 synchronized 锁成功之后，还会判断如果是广播模式，则直接进行消费，如果是集群模式，则判断如果MessageQueue 没有锁住或者锁过期(默认30000ms)，那么延迟100ms后再次尝试向Broker 申请锁定MessageQueue ，锁定成功后重新提交消费请求。

> 有序模式的两个问题：
>
> - 加了过多的锁，降低吞吐量。
> - 前一个消息异常重试时后面的消息都会被阻塞，重试最大次数是`Integer.MAX_VALUE`，每次间隔一秒，所以需要自定义一个重试次数。

**全局有序**

全局有序那就是生产者和消费者参与的queue只有一个，当只有一个messsageQueue时，producer同步写，consumer去消费，这样就能保证全局顺序了，但是一个messageQueue时，会存在性能瓶颈。

> 无论是分区有序还是全局有序，都是建立在同步写的基础上的，异步写不可以。

### kafka

kafka 其实和RocketMQ非常向，不过是 MessageQueue 改成了 Partition 。

在 kafka 中 Partition(分区)是真正保存消息的地方，发送的消息都存放在这里，一个Topic（主题）可以指定多个Partition(分区)。

在Kafka中，只保证Partition(分区)内有序，不保证Topic所有分区都是有序的。

所以 Kafka 要保证消息的消费顺序，可以有2种方法：

- 一个Topic 只创建一个Partition，这样生产者的所有数据都发送到了一个Partition，保证了消息的消费顺序。类似RocketMQ的全局有序。
- 生产者在发送消息的时候指定要发送到哪个Partition。类似RocketMQ的分区有序。

> 这里还有一个问题就是kafka的多线程消费模型，它并不像RocketMQ那样有加锁机制，而单线程效率又不高，所以这里参考RocketMQ的加锁机制设计就好了。

> 补充顺序问题：
>
> 如果设置 max.in.flight.requests.per.connection > 1（默认5，**单个连接上发送的未确认请求的最大数量**，表示上一个发出的请求没有确认下一个请求又发出了）。大于1可能会改变记录的顺序，因为如果将两个 batch 发送到单个分区，第一个 batch 处理失败并重试，但是第二个 batch 处理成功，那么第二个 batch 处理中的记录可能先出现被消费。
>
> 设置 max.in.flight.requests.per.connection = 1，可能会影响吞吐量，可以解决单个生产者发送顺序问题。如果多个生产者，生产者1先发送一个请求，生产者2后发送请求，此时生产者1返回可恢复异常，重试一定次数成功了。虽然生产者1先发送消息，但生产者2发送的消息会被先消费。

## 重复消费

正常情况下，消费者在消费消息的时候，消费完毕后，会发送一个确认消息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除。

但是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他的消费者。 

所以只要是消费消息，就要考虑会不会重复消费？能不能避免重复消费？实在避免不了重复消费如何不造成系统异常（幂等性）？

所以我们先看各个MQ为了避免重复消费都做了哪些？再看如何保证接口幂等性？

### RabbitMQ

在RabbitMQ中消息重复分为生产时消息重复和消费时消息重复。

第一个场景，在生产者发送消息给rabbitMQ服务器的时候，有可能因为网络波动等情况，导致生产者收不到rabbitMQ服务器的应答，导致生产者再发送一条消息。

第二个场景，也是因为网络波动等问题，导致rabbitMQ服务器在向消费者发送消息的时候，没有收到消费者的应答，重复向消费者发生消息。

这两个场景，其实最终都是导致消费者重复消费多次消息，所以在一般的场景下，我们只需要在消费者那里做消息重复消费的保障即可。

可以通过redis/mysql 来记录消息消费的状态，比如订单消息，它的 id 肯定是全局唯一的，消费者收到消息先记录入库，状态为未消费，订单创建成功后再改为已消费。每次消费之前都要先查库判断（注意多线程），这样即使收到了重复消费，也不会影响业务。

### RocketMQ

RocketMQ除了上述的两种情况会出现重复消费，还包括重平衡引起的重复消费。

当消息队列 RocketMQ 的 Broker或客户端重启、扩容或缩容时，会触发Rebalance重平衡机制，前一个监听Queue的消费实例拉取的消息未全部ack，新的消费实例监听到这个Queue重新拉取消息，此时消费者可能会收到重复消息。

解决办法同样是用Redis或Mysql来记录消息消息id，每次消费前判断。

### kafka

首先看生产者端，Kafka 的三种消息语义：

- 最多一次（At most once）：消息可能会丢失，但绝不会被重复发送。
- 至少一次（At least once）：消息不会丢失，但有可能被重复发送。
- 仅有一次（Exactly once）：消息不会丢失，也不会被重复发送。

Exactly once 是最理想也是最难实现的，我们需要单独一篇文章分析其相关源码。

再看消费端，kafka实际上有个offset的概念，每个消息写进去，都有一个offset，代表他的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，代表我已经消费过了，下次如果重启，就继续从上次消费到的offset来继续消费。

但是突然的宕机重启，会导致consumer有些消息处理了，但是没来得及提交offset，重启之后，少数消息会再次消费一次。

解决方式依然要看具体业务来实现其幂等性。

### 如何保证接口幂等性？

- 幂等性操作，如update
- 借助数据库主键唯一性
- 借助redis记录唯一id

## 消息丢失

消息丢失可能发生的情况有三种：

- 生产者发送消息，因为网络原因丢失，一般这种情况都会有重试机制。
- 消息还没落盘，MQ本身挂了，没什么好说的。
- 消费者消费时发生了异常，又没有补偿机制，那也就丢了。

### RabbitMQ

**生产者异常**

首先可以通过事务来实现，在生产者在发送数据之前开启事务，然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会受到异常报错，这时就可以回滚事务，然后尝试重新发送；如果收到了消息，那么就可以提交事务。

```java
    /**
     * 	对外发送消息的方法
     * @param message 	具体的消息内容
     * @param properties   额外的附加属性,优先级、延迟时间
     * @throws Exception
     */
    public void send(Object message, Map<String, Object> properties) throws Exception {
    	 //开启事务
        channel.txSelect();
        try{
            rabbitTemplate.convertAndSend("TestDirectExchange", "TestDirectRouting", "hello,i an message");
            //没有问题，则提交事务
            channel.txCommit();
        }catch (Exception e){
            //如果发送消息的时候，出现异常或者错误
            //事务回滚
            channel.txRollback();
 
        }
    
    }
```

缺点：rabbitmq事物已开启，就会变为同步阻塞操作，生产者会阻塞等待是否发送成功，太耗性能会造成吞吐量的下降。

那第二种方法就是开启 confirm 模式，Confirm消息，是指生产者投递消息后，如果Broker收到消息后，会给生产者一个ACK。生产者通过ACK，可以确认这条消息是否正常发送到Broker，这种方式是消息可靠性投递的核心。

```java
        //开启confirm模式
        channel.confirmSelect();
        for(int i=0;i<5;i++){
            //发送5次消息
            rabbitTemplate.convertAndSend("TestDirectExchange", "TestDirectRouting", "hello,i an message");
        }
        //此方法可以得到rabbitMQ服务器返回的结果
        //也可以调用waitForConfirmsOrDie这个方法，这个方法会等到最后一条信息发生完才返回结果，会造成阻塞
        if(channel.waitForConfirms()){
            //发送成功
        }else{
            //可以选择重新发生或者其他操作
        }
```

第三种方式就是回调函数机制，类似第二种。像这种处理方式就要思考是同步还是异步，即在等待ack的过程中，能不能去发下一条消息。

```java
package com.yitiao.component;

import com.rabbitmq.client.AMQP;
import com.rabbitmq.client.Channel;
import org.springframework.amqp.AmqpException;
import org.springframework.amqp.core.MessagePostProcessor;
import org.springframework.amqp.rabbit.connection.CorrelationData;
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.messaging.Message;
import org.springframework.messaging.MessageHeaders;
import org.springframework.messaging.support.MessageBuilder;
import org.springframework.stereotype.Component;

import javax.annotation.Resource;
import java.util.Map;
import java.util.UUID;

@Component
public class RabbitSender {
    @Resource
    private RabbitTemplate rabbitTemplate;
    /**
     * 这里就是确认消息的回调监听接口，用于确认消息是否被broker所收到
     */
    final RabbitTemplate.ConfirmCallback confirmCallback = new RabbitTemplate.ConfirmCallback(){
        /**
         * 	@param correlationData 作为一个唯一的标识
         * 	@param ack broker 是否落盘成功
         * 	@param cause 失败的一些异常信息
         */
        @Override
        public void confirm(CorrelationData correlationData, boolean ack, String cause) {
            System.err.println("消息ACK结果:" + ack + ", correlationData: " + correlationData.getId());
        }
    };

    /**
     * 	对外发送消息的方法
     * @param message 	具体的消息内容
     * @param properties   额外的附加属性,优先级、延迟时间
     * @throws Exception
     */
    public void send(Object message, Map<String, Object> properties) throws Exception {
        MessageHeaders headers = new MessageHeaders(properties);
        Message<?> objectMessage = MessageBuilder.createMessage(message, headers);

        rabbitTemplate.setConfirmCallback(confirmCallback);

//        channel.confirmSelect();
//        channel.txSelect();
        CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString().trim());

        rabbitTemplate.convertAndSend("exchange-1", "springboot.rabbit", objectMessage, new MessagePostProcessor() {
            @Override
            public org.springframework.amqp.core.Message postProcessMessage(org.springframework.amqp.core.Message message) throws AmqpException {
                System.out.println("------post to do");
                return message;
            }
        },correlationData);

    }
}

```

**可靠性投递方案**

![](https://yitiaoit.oss-cn-beijing.aliyuncs.com/img/4636177-911c83939b34bf1b.png)

 

1.将消息落地到业务db和Message db。

 2.采用Confirm方式发送消息至MQ Broker，返回结果的过程是异步的。Confirm消息，是指生产者投递消息后，如果Broker收到消息后，会给生产者一个ACK。生产者通过ACK，可以确认这条消息是否正常发送到Broker，这种方式是消息可靠性投递的核心。

 3、4：在这里将消息分成3种状态。status=0表示消息正在投递中，status=1表示消息投递成功，status=2表示消息投递了3次还是失败。生产者接收Broker返回的Confirm确认消息结果，然后根据结果更新消息的状态。将status的状态从投递中改成投递成功即可。

 5.在消息Confirm过程中，可能由于网络闪断问题或者是Broker端出现异常，导致回送消息失败或者出现异常。这时候，就需要生产者对消息进行可靠性投递，保证投递到Broker的消息可靠不丢失。还有一种极端情况值得我们考虑，那就是网络闪断。我们的消息成功投递到Broker，但是在回送ACK确认消息时，由于网络闪断，生产者没有收到。此时我们再重新投递此消息可能会造成消费端重复消费消息了。这时候需要消费端去做幂等处理(生成全局消息ID，判断此消息是否消费过)。对于没有投递成功的消息，我们可以设置一个重新投递时间。比如一个消息在5分钟内，status状态还是0，也就是这个消息还没有成功投递到Broker端。这时候我们需要一个定时任务，每隔几分钟从Message db中拉取status为0的消息。

 6.将拉取的消息执行重新投递操作。

 7.设置最大消息投递次数。当一个消息被投递了3次，还是不成功，那么将status置为2。最后交给人工解决处理此类问题或者将消息转存到失败表。

**MQ异常**

好，我们回到如果是MQ挂了怎么办？这里就依靠MQ的持久化配置了。

设置持久化有两个步骤，第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据；

第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。

而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。

**消费者异常**

如果是消费者异常怎么办？我们需要关闭自动提交，因为默认情况把消息发到客户端之后，该消息就会从队列删除。

```java
channel.basicConsume("队列名", false, new DefaultConsumer(channel)
```

### RocketMQ

上述三张情况在RocketMQ中依然存在，解决方式无非是事务消息、同步刷盘、同步消费，成功后再返回ack。除了这三种，还有一个特殊情况，这和RocketMQ的过滤机制有关系。

同一个消费组内的消费者，如果订阅了相同的Topic，但是订阅的tag不相同，会出现消息丢失问题。

https://blog.csdn.net/lzy194/article/details/122037615

### kafka

Kafka是一个靠配置解决可靠性投递的消息队列，还记得消息语义吗？有个丢消息有关的。

除此之外，Kafka的分区副本机制也会带来丢失问题，比如选举新leader的时候恰好有几条消息还没有同步到follower，所以下面这几条配置就很关键。

- topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本。
- 服务端设置min.insync.replicas参数：这个值必须大于1，要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower。
- 在producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了。
- 在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。

按照以上的配置，生产者一定是把消息发到了所有分区副本，那即使某一个broker挂了，也不影响，而消费者自然就是要把offset提交了才认为消费成功了。

## 总结

写到这里已经是 12000 多字。但其实能讲的东西还有很多，关于消息队列的问题也还有很多，比如消息堆积、事务消息、延迟消息、消息存储以及底层的网络通信、长轮询机制、负载均衡等等等。

![](https://yitiaoit.oss-cn-beijing.aliyuncs.com/img/image-20220707222324521.png)

每个消息队列的不同设计都是有其应用场景的，我们不必了解每个的源码，但基本的原理和流程要知道，这才能做技术选型和评估。

本期就到这里，要理解，更要背。以后还是会像这样一个问题把三大MQ的解决方案都说了。下期见！









 