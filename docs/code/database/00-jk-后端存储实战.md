



## 异构数据库实时同步

数据量大————分库分表————复杂查询————ES再存一份（多份）————各系统间数据如何实时同步？

早期使用ETL定时同步，但是无法做到实时性。

后来阿里淘宝团队为解决异地机房数据同步问题，开发了Canal，并开源，其伪装成Slave读取binlog。

![](https://yitiaoit.oss-cn-beijing.aliyuncs.com/img/dfa37d67d87fc7c8a8de50681f8134d8.jpg)

Canal 从 MySQL 收到 Binlog 并解析成结构化数据之后，直接写入到 MQ 的一个订单 Binlog 主题中，然后每一个需要同步订单数据的业务方，都去订阅这个 MQ 中的订单 Binlog 主题，消费解析后的 Binlog 数据。在每个消费者自己的同步程序中，它既可以直接入库，也可以做一些数据转换、过滤或者计算之后再入库，这样就比较灵活了。

**如何保证高实时性**

1.多线程可以吗？

盲目的多线程或多机器消费会导致消费乱序问题

2.不同订单分区消费

通过哈希算法将相同的订单分到同一分区，保证局部有序即可，Canal支持分区策略，[文档](https://github.com/alibaba/canal/wiki/Canal-Kafka-RocketMQ-QuickStart)。

**如何回退消费**

在我们这种数据同步架构下，如果说下游的某个同步程序或数据库出了问题，需要把 Binlog 回退到某个时间点然后重新同步，这个问题该怎么解决？

> 把binlog回退到某个时间点开始重新同步，这个需要mq消费端的消费进度支持重置，重置到过去的某一个消费进度就可以了
>
> 本身row格式的binlog就是幂等的，mq也要求消费者必须具备幂等性。 所以，自然就支持重置。

**分区如何扩容**

1. 停掉Canel； 
2. 等MQ中所有的消息都消费完了。 
3. 扩容MQ分区数，增加消费者实例数量。
4. 重新启动Canel。