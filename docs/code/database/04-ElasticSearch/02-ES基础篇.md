## 倒排索引

> https://www.cnblogs.com/jajian/p/10465519.html
>
> [官方文档](https://www.elastic.co/cn/blog/frame-of-reference-and-roaring-bitmaps)

在没有搜索引擎时，我们是直接输入一个网址，然后获取网站内容，这时我们的行为是：

```
document -> to -> words
```

通过文章，获取里面的单词，此谓「正向索引」，forward index.

后来，我们希望能够输入一个单词，找到含有这个单词，或者和这个单词有关系的文章：

```
word -> to -> documents
```

于是我们把这种索引，成为inverted index，直译过来，应该叫「反向索引」，国内翻译成「倒排索引」

**玩具版**

首先，在数据生成的时候，比如有一篇文章，首先需要将文本拆解成一个个单词。

这个过程很复杂，比如“生存还是死亡”，你要如何让分词器自动将它分解为“生存”、“还是”、“死亡”三个词语，然后把“还是”这个无意义的词语干掉，这里不展开。

接着，把这两个词语以及它对应的文档（文章）id存下来：

| word | documentId |
| ---- | ---------- |
| 生存 | 1          |
| 死亡 | 1          |

接着爬虫继续爬，又爬到一个含有“生存”的文档，于是索引变成：

| word | documentId |
| ---- | ---------- |
| 生存 | 1,2        |
| 死亡 | 1          |

为什么说是玩具版呢？想想看，这个世界上那么多单词，中文、英文、日文、韩文 … 你每次搜索一个单词，我都要全局遍历一遍，很明显不行。

**生产版**

如何快速的搜索到查找的单词呢，mysql有B+树，我们要照着学一下，为单词再建一层索引


![](https://yitiaoit.oss-cn-beijing.aliyuncs.com/img/image-20230130154214413.png)

生产版增加了最左边的一层「字典树」term index，它不存储所有的单词，只存储单词前缀，通过字典树找到单词所在的块，也就是单词的大概位置，再在块里二分查找，找到对应的单词，再找到单词对应的文档列表。

当然，内存寸土寸金，能省则省，所以 Lucene 还用了 FST（Finite State Transducers）对它进一步压缩。


我们再看文档列表，原生的 Posting List 有两个痛点：

- 如何压缩以节省`磁盘空间`
- 如何快速求交并集（intersections and unions）

假设这样一个数组：

```
[73, 300, 302, 332, 343, 372]
```

先看压缩，计算一下不压缩占多大空间，Lucene 里，数据是按 Segment 存储的，每个 Segment 最多存 65536 个文档 ID， 所以文档 ID 的范围，从 0 到 2^16-1，所以如果不进行任何处理，那么每个元素都会占用 2 bytes（8bit） ，对应上面的数组，就是 6 * 2 = 12 bytes.

`压缩，就是尽可能降低每个数据占用的空间，同时又能让信息不失真，能够还原回来。`

看一下压缩的过程：

1.增量编码,即只记录元素间的增量（已排好序）

```
[73, 227, 2, 30, 11, 29]
```

2.分块处理，防止大数拖累小数

Lucene里每个块是 256 个文档 ID，这样可以保证每个块，增量编码后，每个元素都不会超过 256（1 byte）.

为了方便演示，我们假设每个块是 3 个文档 ID：

```
[73, 227, 2], [30, 11, 29]
```

3.按需分配空间,每一块取最大的数所需要的字节空间

对于第一个块，[73, 227, 2]，最大元素是227，需要 8 bits，好，那我给你这个块的每个元素，都分配 8 bits的空间。

但是对于第二个块，[30, 11, 29]，最大的元素才30，只需要 5 bits，那我就给你每个元素，只分配 5 bits 的空间，足矣。

![](https://yitiaoit.oss-cn-beijing.aliyuncs.com/img/image-20230130163214403.png)

> 以上解决了如何节约磁盘空间，但是解压缩是需要消耗cpu的，跳表能提高查询的效率。

再看如何求交集：

由于ES是分片存储的，再加上复杂的条件查询，求交集的操作无处不在，假设下面三个数组求交集：

```
[64, 300, 303, 343]
[73, 300, 302, 303, 343, 372]
[303, 311, 333, 343]
```

首先还是占用空间的问题，计算交集的过程是发生在内存，更是寸土寸金，用数组存储万万不可。

首先采用bitmap，用0/1表示某个值是否存在，比如8这个值就对应第8位，对应的bit值是1，这样用一个字节就可以代表8个文档id（1B = 8bit）

```
[3,1,4,7,8]  ->  [0,1,0,1,1,0,0,1,1]
```



如果文档有数十亿之多，或某些极端数组[0, 65535]，采用bitmap+数组并存的方式，即位图压缩算法——BMP

![](https://yitiaoit.oss-cn-beijing.aliyuncs.com/img/image-20230130164949145.png)

4096如何计算：

无论文档数量多少，bitmap都需要 8192 bytes，而 Integer 数组则和文档数量成线性相关，每个文档 ID 占 2 bytes，所以：`8192 / 2 = 4096`，当文档数量少于 4096 时，用 Integer 数组，否则，用 bitmap.

另外，Lucene 还会把从磁盘取出来的数据，通过 Roaring bitmaps 处理后，缓存到内存中，Lucene 称之为 filter cache。



